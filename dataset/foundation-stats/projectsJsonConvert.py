import json
import csv
import requests

# Load JSON data
with open('projects.json', 'r', encoding='utf-8') as json_file:
    data = json.load(json_file)


# Define CSV columns
csv_columns = [
    "name", "path", "description", "homepage_url", "project", "repo_url", 
    "logo", "twitter", "crunchbase", "chat_channel", "accepted", 
    "dev_stats_url", "artwork_url", "stack_overflow_url", "blog_url", 
    "mailing_list_url", "slack_url", "gitter_url", "youtube_url", "language"
]

# Prepare data for CSV
csv_data = []
for item in data:
    # Skip the autogenerated metadata entry
    if item.get("IMPORTANT") or item.get("COMMENT") or item.get("project") == "AUTOGENERATED":
        continue

    row = {
        "name": item.get("name", ""),
        "path": item.get("path", ""),
        "description": item.get("description", ""),
        "homepage_url": item.get("homepage_url", ""),
        "project": item.get("project", ""),
        "repo_url": item.get("repo_url", ""),
        "logo": item.get("logo", ""),
        "twitter": item.get("twitter", ""),
        "crunchbase": item.get("crunchbase", ""),
        "chat_channel": item.get("chat_channel", ""),
        "accepted": item.get("accepted", ""),
        "dev_stats_url": item.get("dev_stats_url", ""),
        "artwork_url": item.get("artwork_url", ""),
        "stack_overflow_url": item.get("stack_overflow_url", ""),
        "blog_url": item.get("blog_url", ""),
        "mailing_list_url": item.get("mailing_list_url", ""),
        "slack_url": item.get("slack_url", ""),
        "gitter_url": item.get("gitter_url", ""),
        "youtube_url": item.get("youtube_url", ""),
        "language": item.get("language", "")
    }
    csv_data.append(row)

# Write to CSV
with open('website_data_projects.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=csv_columns)
    writer.writeheader()
    for row in csv_data:
        writer.writerow(row)

print("CSV file created successfully: output.csv")